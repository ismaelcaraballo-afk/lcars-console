// IMPROVED_AIChat.tsx
// Optimized with security, performance, and error handling improvements

import { useState, useRef, useEffect, useMemo, useCallback } from "react";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Textarea } from "@/components/ui/textarea";
import { MessageSquare, Send, Sparkles, AlertCircle, Clock } from "lucide-react";
import { useToast } from "@/hooks/use-toast";
import {
  validateMessage,
  RateLimiter,
  safeFetchJSON,
  analyzeSentiment,
  parseError,
  formatRateLimitStatus,
  RATE_LIMITS,
  TIMEOUTS,
  MESSAGE_LIMITS,
  type SentimentResult,
} from "./utilities";

interface Message {
  role: "user" | "assistant" | "system";
  content: string;
  timestamp: Date;
}

// RATE LIMITER INSTANCES
// Create outside component to persist across renders
// Adjust these based on your Claude API plan
const aiRateLimiter = new RateLimiter(
  RATE_LIMITS.CLAUDE_AI.maxCalls,     // 5 calls per minute (conservative for Claude API)
  RATE_LIMITS.CLAUDE_AI.timeWindow
);

const localRateLimiter = new RateLimiter(
  RATE_LIMITS.LOCAL.maxCalls,         // 30 calls per minute for local NLP
  RATE_LIMITS.LOCAL.timeWindow
);

export default function AIChat() {
  const { toast } = useToast();
  const [messages, setMessages] = useState<Message[]>([
    {
      role: "system",
      content: "ðŸ¤– LCARS AI Assistant Online. I can help you with natural language queries, task management, and general assistance.",
      timestamp: new Date(),
    },
  ]);
  const [input, setInput] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [rateLimitInfo, setRateLimitInfo] = useState<string>("");
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // OPTIMIZATION: Memoize sentiment calculation
  const currentSentiment = useMemo<SentimentResult>(
    () => analyzeSentiment(input),
    [input]
  );

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  // Update rate limit info periodically
  useEffect(() => {
    const updateRateLimit = () => {
      setRateLimitInfo(formatRateLimitStatus(aiRateLimiter));
    };
    
    updateRateLimit();
    const interval = setInterval(updateRateLimit, 5000); // Update every 5 seconds
    
    return () => clearInterval(interval);
  }, []);

  // Process voice commands from sessionStorage
  useEffect(() => {
    const voiceCommand = sessionStorage.getItem("voiceCommand");
    if (voiceCommand) {
      sessionStorage.removeItem("voiceCommand");
      setInput(voiceCommand);
      
      setTimeout(() => {
        if (voiceCommand.trim()) {
          processMessage(voiceCommand);
        }
      }, 500);
    }
  }, []);

  // OPTIMIZATION: Extract common NLP processing
  const processNaturalLanguage = useCallback(async (text: string): Promise<string> => {
    const lower = text.toLowerCase();
    let responses: string[] = [];

    const hasTime = /time|clock|stardate/i.test(lower);
    const hasWeather = /weather|temperature|forecast/i.test(lower);
    const hasTasks = /task|todo|to-do|reminder/i.test(lower);
    const hasStatus = /status|health|system|diagnostic/i.test(lower);
    const hasJoke = /joke|funny|laugh/i.test(lower);
    const hasGreeting = /^(hi|hello|hey|greetings)/i.test(lower);
    const hasThanks = /thank|thanks/i.test(lower);
    const hasSwallow = /swallow|african|european/i.test(lower);

    if (hasGreeting) {
      return "Hello! I'm your LCARS AI assistant. How can I help you today?";
    }

    if (hasThanks) {
      return "You're welcome! I'm always here to assist you.";
    }

    if (hasTime) {
      const now = new Date();
      const stardate = (41000.0 + (Date.now() % 31536000000) / 31536000).toFixed(2);
      responses.push(`â° TIME: ${now.toLocaleTimeString()} | Stardate: ${stardate}`);
    }

    if (hasTasks) {
      try {
        const tasks = await safeFetchJSON("/api/tasks", {}, TIMEOUTS.SHORT);
        const activeTasks = tasks.filter((t: any) => t.status === "active");
        const completed = tasks.filter((t: any) => t.status === "completed");
        
        responses.push(`ðŸ“‹ TASKS: ${activeTasks.length} active, ${completed.length} completed`);
        
        if (activeTasks.length > 0) {
          const topTasks = activeTasks.slice(0, 3).map((t: any) => `  â€¢ ${t.title}`).join('\n');
          responses.push(`Top priorities:\n${topTasks}`);
        }
      } catch (error) {
        responses.push(`ðŸ“‹ TASKS: Unable to fetch task data`);
      }
    }

    if (hasWeather) {
      try {
        const weather = await safeFetchJSON("/api/weather/current", {}, TIMEOUTS.SHORT);
        responses.push(`ðŸŒ¤ï¸ WEATHER: ${weather.temp}Â°C, ${weather.condition} in ${weather.city}`);
      } catch (error) {
        responses.push(`ðŸŒ¤ï¸ WEATHER: Unable to fetch weather data`);
      }
    }

    if (hasStatus) {
      responses.push(`ðŸ’š SYSTEM STATUS: All LCARS systems NOMINAL\n  â€¢ Core: OPERATIONAL\n  â€¢ AI Module: READY\n  â€¢ Storage: ACTIVE`);
    }

    if (hasJoke) {
      const jokes = [
        "Why do programmers prefer dark mode? Because light attracts bugs! ðŸ˜„",
        "How many programmers does it take to change a light bulb? None, that's a hardware problem!",
        "Why did the developer go broke? Because he used up all his cache!",
        "What's the object-oriented way to become wealthy? Inheritance! ðŸ’°",
      ];
      responses.push(`ðŸ˜„ ${jokes[Math.floor(Math.random() * jokes.length)]}`);
    }

    if (hasSwallow) {
      responses.push(`ðŸ¦ SWALLOW ANALYSIS:\nAfrican Swallow: Unladen airspeed ~24 mph (non-migratory)\nEuropean Swallow: Unladen airspeed ~20.1 mph\n\nNote: Swallows cannot carry coconuts. Bridge of Death protocols do not apply here.`);
    }

    if (responses.length > 0) {
      return responses.join('\n\n');
    }

    if (/about|what is|tell me about|explain/i.test(lower) && !hasSwallow) {
      return "I'm the LCARS AI Console - a Star Trek-themed productivity dashboard. I can help with task management, weather info, analytics, and natural language processing.";
    }

    if (/api|claude|anthropic/i.test(lower)) {
      return "ðŸ¤– Claude AI Integration is ready to activate! Add your ANTHROPIC_API_KEY to .env to enable advanced AI conversations. See API-ALTERNATIVES.md for other options (OpenAI, Gemini, Perplexity).";
    }

    return "I understand you're asking about: " + text + ". While I have basic natural language processing, adding a Claude AI API key will unlock much more powerful conversations and understanding. See the Settings panel for API configuration.";
  }, []);

  // SECURITY & PERFORMANCE: Unified message processor
  const processMessage = useCallback(async (messageText: string) => {
    // STEP 1: VALIDATION & SANITIZATION
    const validation = validateMessage(messageText, MESSAGE_LIMITS.LONG);
    
    if (!validation.valid) {
      toast({
        title: "Invalid message",
        description: validation.error,
        variant: "destructive",
      });
      return;
    }

    // STEP 2: RATE LIMITING CHECK
    // Try AI rate limiter first
    const useClaudeAPI = aiRateLimiter.canMakeCall();
    
    // If Claude API is rate limited, check local NLP limiter
    if (!useClaudeAPI && !localRateLimiter.canMakeCall()) {
      const timeRemaining = aiRateLimiter.getTimeUntilNextCall();
      const seconds = Math.ceil(timeRemaining / 1000);
      
      toast({
        title: "Rate limit exceeded",
        description: `Please wait ${seconds} seconds before sending another message.`,
        variant: "destructive",
      });
      return;
    }

    // STEP 3: CREATE USER MESSAGE (with sanitized content)
    const userMessage: Message = {
      role: "user",
      content: validation.sanitized!,
      timestamp: new Date(),
    };

    setMessages((prev) => [...prev, userMessage]);
    setInput("");
    setIsProcessing(true);

    try {
      let aiResponse: string;

      if (useClaudeAPI) {
        // TRY CLAUDE API WITH TIMEOUT
        try {
          console.log('ðŸ¤– Attempting Claude AI request...');
          
          const data = await safeFetchJSON(
            "/api/ai/chat",
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ message: validation.sanitized }),
            },
            TIMEOUTS.LONG // 30 second timeout for AI responses
          );

          if (data.error && data.apiAvailable === false) {
            console.log('âš ï¸ Claude API not available, using local NLP');
            // Use local rate limiter for fallback
            if (!localRateLimiter.canMakeCall()) {
              throw new Error('Local NLP rate limit exceeded');
            }
            aiResponse = await processNaturalLanguage(validation.sanitized!);
          } else {
            console.log('âœ… Claude AI response received');
            aiResponse = data.response;
          }
        } catch (apiError) {
          console.error('âŒ Claude API error:', apiError);
          
          // Fallback to local NLP
          if (!localRateLimiter.canMakeCall()) {
            throw new Error('Both AI and local NLP rate limits exceeded');
          }
          
          const errorInfo = parseError(apiError);
          
          if (errorInfo.retryable) {
            toast({
              title: "API Error",
              description: errorInfo.userMessage,
              variant: "destructive",
            });
          }
          
          console.log('ðŸ”„ Falling back to local NLP');
          aiResponse = await processNaturalLanguage(validation.sanitized!);
        }
      } else {
        // USE LOCAL NLP (rate limited separately)
        console.log('ðŸ”„ Using local NLP (Claude API rate limited)');
        aiResponse = await processNaturalLanguage(validation.sanitized!);
      }

      // STEP 4: ADD AI RESPONSE
      const assistantMessage: Message = {
        role: "assistant",
        content: aiResponse,
        timestamp: new Date(),
      };

      setMessages((prev) => [...prev, assistantMessage]);
      
      // Update rate limit display
      setRateLimitInfo(formatRateLimitStatus(aiRateLimiter));

    } catch (error) {
      console.error('âŒ Message processing error:', error);
      
      const errorInfo = parseError(error);
      
      toast({
        title: "Error",
        description: errorInfo.userMessage,
        variant: "destructive",
      });

      // Add error message to chat
      const errorMessage: Message = {
        role: "assistant",
        content: `âš ï¸ Error: ${errorInfo.userMessage}. Please try again.`,
        timestamp: new Date(),
      };
      
      setMessages((prev) => [...prev, errorMessage]);
      
    } finally {
      setIsProcessing(false);
      setRateLimitInfo(formatRateLimitStatus(aiRateLimiter));
    }
  }, [toast, processNaturalLanguage]);

  const handleSend = useCallback(() => {
    processMessage(input);
  }, [input, processMessage]);

  const handleKeyPress = useCallback((e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  }, [handleSend]);

  return (
    <div className="p-6 space-y-6">
      <div>
        <h1 className="text-3xl font-bold text-primary lcars-glow flex items-center gap-2" data-testid="text-page-title">
          <MessageSquare className="h-8 w-8" />
          AI Assistant
        </h1>
        <p className="text-muted-foreground" data-testid="text-page-subtitle">
          Natural language interface
        </p>
      </div>

      {/* Rate Limit Status Banner */}
      {rateLimitInfo && (
        <Card className="bg-muted/50 border-primary/20">
          <CardContent className="py-3 px-4 flex items-center gap-2 text-sm">
            <Clock className="h-4 w-4 text-primary" />
            <span className="text-muted-foreground">{rateLimitInfo}</span>
          </CardContent>
        </Card>
      )}

      {/* Quick Actions */}
      <Card className="lcars-scanner">
        <CardHeader>
          <CardTitle className="text-sm text-primary">Quick Questions</CardTitle>
        </CardHeader>
        <CardContent className="flex flex-wrap gap-2">
          <Button
            size="sm"
            variant="outline"
            onClick={() => setInput("What's the weather?")}
            data-testid="button-quick-weather"
          >
            What's the weather?
          </Button>
          <Button
            size="sm"
            variant="outline"
            onClick={() => setInput("Show my tasks")}
            data-testid="button-quick-tasks"
          >
            Show my tasks
          </Button>
          <Button
            size="sm"
            variant="outline"
            onClick={() => setInput("Tell me a joke")}
            data-testid="button-quick-joke"
          >
            Tell me a joke
          </Button>
          <Button
            size="sm"
            variant="outline"
            onClick={() => setInput("System status")}
            data-testid="button-quick-status"
          >
            System status
          </Button>
        </CardContent>
      </Card>

      {/* Chat Messages */}
      <Card className="lcars-scanner">
        <CardContent className="p-6">
          <div className="h-96 overflow-y-auto mb-4 space-y-4" data-testid="chat-messages">
            {messages.map((msg, i) => (
              <div
                key={i}
                className={`p-3 rounded-md ${
                  msg.role === "user"
                    ? "bg-primary/20 border-l-4 border-primary ml-12"
                    : msg.role === "assistant"
                    ? "bg-secondary/20 border-l-4 border-secondary mr-12"
                    : "bg-muted/50 text-center"
                }`}
                data-testid={`message-${i}`}
              >
                <div className="text-sm whitespace-pre-wrap">{msg.content}</div>
                <div className="text-xs text-muted-foreground mt-2">
                  {msg.timestamp.toLocaleTimeString()}
                </div>
              </div>
            ))}
            {isProcessing && (
              <div className="bg-secondary/20 border-l-4 border-secondary p-3 rounded-md mr-12 lcars-pulse">
                <div className="text-sm">AI is thinking...</div>
              </div>
            )}
            <div ref={messagesEndRef} />
          </div>

          <div className="space-y-4">
            <Textarea
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={handleKeyPress}
              placeholder="Ask me anything... (natural language supported)"
              className="resize-none"
              rows={3}
              maxLength={MESSAGE_LIMITS.LONG}
              data-testid="input-ai-chat"
            />
            <div className="flex items-center justify-between">
              <div className="flex items-center gap-4 text-sm">
                <div>
                  <span className="text-muted-foreground">Mood:</span>{" "}
                  <span className="font-mono" data-testid="text-sentiment-mood">
                    {currentSentiment.icon} {currentSentiment.mood}
                  </span>
                </div>
                <div>
                  <span className="text-muted-foreground">Score:</span>{" "}
                  <span className="font-mono" data-testid="text-sentiment-score">
                    {currentSentiment.score > 0 ? "+" : ""}
                    {currentSentiment.score}
                  </span>
                </div>
                <div className="text-xs text-muted-foreground">
                  {input.length}/{MESSAGE_LIMITS.LONG} chars
                </div>
              </div>
              <Button
                onClick={handleSend}
                disabled={isProcessing || !input.trim()}
                data-testid="button-send-message"
              >
                <Send className="h-4 w-4 mr-2" />
                Send
              </Button>
            </div>
          </div>
        </CardContent>
      </Card>

      {/* AI Capabilities */}
      <Card className="lcars-scanner">
        <CardHeader>
          <CardTitle className="text-primary flex items-center gap-2">
            <Sparkles className="h-5 w-5" />
            AI Capabilities & Status
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid gap-3 md:grid-cols-2">
            <div className="p-3 rounded-md bg-muted">âœ… Natural Language Understanding</div>
            <div className="p-3 rounded-md bg-muted">âœ… Context-Aware Responses</div>
            <div className="p-3 rounded-md bg-muted">âœ… Sentiment Analysis (Optimized)</div>
            <div className="p-3 rounded-md bg-muted">âœ… Task Management Help</div>
            <div className="p-3 rounded-md bg-muted">âœ… Information Retrieval</div>
            <div className="p-3 rounded-md bg-muted">âœ… Star Trek Roleplay</div>
            <div className="p-3 rounded-md bg-green-500/20">âœ… Input Sanitization (XSS Protected)</div>
            <div className="p-3 rounded-md bg-green-500/20">âœ… Rate Limiting (API Protected)</div>
          </div>
          
          <div className="mt-4 p-3 rounded-md bg-primary/10 border border-primary/20 text-sm">
            <div className="font-semibold text-foreground mb-2 flex items-center gap-2">
              <AlertCircle className="h-4 w-4" />
              Security & Performance Features
            </div>
            <ul className="text-muted-foreground space-y-1 ml-6 list-disc">
              <li>Input validation and XSS protection</li>
              <li>Smart rate limiting (5 AI calls/min, 30 local/min)</li>
              <li>Automatic fallback to local NLP</li>
              <li>Request timeout protection (30s max)</li>
              <li>Optimized sentiment analysis (O(n) complexity)</li>
            </ul>
          </div>
          
          <div className="mt-4 p-3 rounded-md bg-warning/20 text-sm">
            <div className="font-semibold text-foreground mb-1">ðŸ¤– Enhanced AI Available</div>
            <div className="text-muted-foreground">
              Add <span className="text-primary font-mono">ANTHROPIC_API_KEY</span> to enable Claude AI for much more powerful conversations.
              Rate limited to 5 calls/minute to protect your API usage.
            </div>
          </div>
        </CardContent>
      </Card>
    </div>
  );
}